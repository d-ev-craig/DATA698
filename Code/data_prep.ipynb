{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guide to this File:\n",
    "\n",
    "This file is intended to be ran from other notebooks. This file will create the following objects:\n",
    "\n",
    "df : match data [match_id, hero_id, gold_t]\n",
    "df_no_match : match data without match_id [hero_id, gold_t]\n",
    "\n",
    "missing_indices : indices that had missing gold_t values and were removed, use with print() to view\n",
    "df.loc[missing_indices, ['hero_id','gold_t']] : to be used to view missing_indices\n",
    "\n",
    "zero_length_indices : the indices containing zero length gold_t values and were removed\n",
    "zero_length_records : the records containing zero length gold_t values and were removed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import requests\n",
    "from numpy import array\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Used in LTSMModel Class Instantiation\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Load\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\dcrai\\\\source\\\\repos\\\\DATA698\\\\Code\\\\Data\\\\data.json\"\n",
    "file_path_hero = \"C:\\\\Users\\\\dcrai\\\\source\\\\repos\\\\DATA698\\\\Code\\\\Data\\\\hero_id_table.csv\"\n",
    "#file_csv = \"C:\\\\Users\\\\dcrai\\\\source\\\\repos\\\\DATA698\\\\Code\\\\Data\\\\iter_1.csv\" - different match data\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Github Load\n",
    "\n",
    "#file_path = \"https://raw.githubusercontent.com/d-ev-craig/DATA698/main/Code/Data/data.json\"\n",
    "#file_path_hero = \"https://raw.githubusercontent.com/d-ev-craig/DATA698/main/Code/Data/hero_id_table.csv\"\n",
    "\n",
    "#response = requests.get(file_path)\n",
    "#data = json.loads(response.text)\n",
    "\n",
    "# Create heroes dataframe\n",
    "heroes= pd.read_csv(file_path_hero)\n",
    "\n",
    "# Extract 'match_id', 'hero_id', and 'gold_t' from each element in 'data'\n",
    "match_ids = [element['match_id'] for element in data]\n",
    "hero_ids = [element['hero_id'] for element in data]\n",
    "gold_t_values = [element['gold_t'] for element in data]\n",
    "\n",
    "# Create match data dataframe\n",
    "df = pd.DataFrame({'match_id': match_ids, 'hero_id': hero_ids, 'gold_t': gold_t_values})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match ID example\n",
    "#7517376613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking zero length tensors\n",
    "\n",
    "#df.iloc[2470]\n",
    "#df.iloc[2511]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_mask = df['gold_t'].isnull()\n",
    "missing_indices = df.index[missing_mask]\n",
    "#print(missing_indices)\n",
    "df.loc[missing_indices, ['hero_id','gold_t']]\n",
    "\n",
    "df = df.dropna(subset=['gold_t'])\n",
    "df = df.reset_index(drop=True) # Reset the indexes so no issues arise with using index locations to drop 0 length tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Length Tensors Drop\n",
    "\n",
    "If we don't drop the zero length tensors, when we call `model(hero_ids,time_series)` in the training loop, it will error out when attempting to run pad_packed_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 tensors with length 0 at indices: [2460, 2501, 2512, 2583]\n"
     ]
    }
   ],
   "source": [
    "zero_length_indices = []\n",
    "\n",
    "for index, time_series in enumerate(df['gold_t']):\n",
    "    if len(time_series) == 0:\n",
    "        zero_length_indices.append(index)\n",
    "\n",
    "if len(zero_length_indices) > 0:\n",
    "    print(f\"Found {len(zero_length_indices)} tensors with length 0 at indices: {zero_length_indices}\")\n",
    "else:\n",
    "    print(\"No tensors with length 0 found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_length_records = df.loc[zero_length_indices, ['hero_id','gold_t']]\n",
    "\n",
    "#df_full.iloc[2583][['hero_id','gold_t']]\n",
    "#len(df_full.iloc[2460]['gold_t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different methods to reduce data size for testing\n",
    "\n",
    "#df_match = df[df['match_id'] == 7517376613]\n",
    "#df_match = df[:300]\n",
    "#df_match\n",
    "\n",
    "#df_subset = df_match[['hero_id', 'gold_t']].copy()\n",
    "#df_subset\n",
    "\n",
    "df_no_match = df[['hero_id', 'gold_t']].copy()\n",
    "df_no_match = df_no_match.drop(zero_length_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df_subset.gold_t\n",
    "\n",
    "# from pandas import Series\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # define contrived series\n",
    "# series = data.apply(pd.Series)\n",
    "# print(series)\n",
    "\n",
    "# # prepare data for normalization\n",
    "# values = series.values\n",
    "\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaler = scaler.fit(values)\n",
    "# print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
    "\n",
    "# #values = values.reshape((len(values), 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
