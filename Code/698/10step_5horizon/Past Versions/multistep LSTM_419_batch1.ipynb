{"cells":[{"cell_type":"code","execution_count":104,"metadata":{"id":"dx-wxtGvj5w7","executionInfo":{"status":"ok","timestamp":1714426390807,"user_tz":240,"elapsed":173,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["import json\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","\n","#from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDlqrOEAkcLO","executionInfo":{"status":"ok","timestamp":1714426392891,"user_tz":240,"elapsed":1008,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}},"outputId":"78c3fdea-b448-4f20-c053-fe8f678637d1"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/698/\")"],"metadata":{"id":"3N75xrN6kc8f","executionInfo":{"status":"ok","timestamp":1714426415471,"user_tz":240,"elapsed":340,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","execution_count":109,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3s39p0k_j5w9","executionInfo":{"status":"ok","timestamp":1714426434930,"user_tz":240,"elapsed":18029,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}},"outputId":"4dfe0014-7e80-4b90-d8a1-ba74501ec7b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["      hero_id gold_t\n","2270       20   None\n","2271      120   None\n","2272       69   None\n","2273       73   None\n","2274       26   None\n","...       ...    ...\n","6915      136   None\n","6916      106   None\n","6917      137   None\n","6918       14   None\n","6919      112   None\n","\n","[76 rows x 2 columns]\n","      hero_id gold_t\n","2270       20   None\n","2271      120   None\n","2272       69   None\n","2273       73   None\n","2274       26   None\n","...       ...    ...\n","6915      136   None\n","6916      106   None\n","6917      137   None\n","6918       14   None\n","6919      112   None\n","\n","[76 rows x 2 columns]\n","Found 194 tensors with length 0 at indices: [230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 2460, 2501, 2512, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3582, 3583, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4371, 4372, 4373, 5334, 5335, 5336, 5337, 5338, 5339, 5340, 5341, 5342, 5343, 5414, 5415, 5416, 5417, 5418, 5419, 5420, 5421, 5422, 5423, 8094, 8095, 8096, 8097, 8098, 8099, 8100, 8101, 8102, 8103, 9524, 9525, 9526, 9527, 9528, 9529, 9530, 9531, 9532, 9533]\n","Found 194 tensors with length 0 at indices: [230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 2460, 2501, 2512, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3582, 3583, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4371, 4372, 4373, 5334, 5335, 5336, 5337, 5338, 5339, 5340, 5341, 5342, 5343, 5414, 5415, 5416, 5417, 5418, 5419, 5420, 5421, 5422, 5423, 8094, 8095, 8096, 8097, 8098, 8099, 8100, 8101, 8102, 8103, 9524, 9525, 9526, 9527, 9528, 9529, 9530, 9531, 9532, 9533]\n","6924\n","2976\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["%run data_prep_one_hero_10step_5horizon.ipynb\n","\n","#torch.load(df_allhero, 'df_allhero.pt')\n","#torch.load(hero_ids, 'hero_ids.pt')\n","#torch.load(df_all_remain, 'df_all_remain.pt')\n","\n","#torch.load(df2_allhero, 'df2_allhero.pt')\n","#torch.load(hero_ids2, 'hero_ids2.pt')\n","#torch.load(df2_all_remain, 'df2_all_remain.pt')"]},{"cell_type":"code","source":["#df2_allhero_avglen"],"metadata":{"id":"xAkelUZRXnsG","executionInfo":{"status":"aborted","timestamp":1714426392892,"user_tz":240,"elapsed":7,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWSC-SpZj5w-","executionInfo":{"status":"aborted","timestamp":1714426392892,"user_tz":240,"elapsed":2404,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["#len(df_allhero.iloc[0]['gold_t'])"]},{"cell_type":"markdown","metadata":{"id":"S2LbZpekj5w-"},"source":["### TimeSeriesDataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LyuKx4qj5w_","executionInfo":{"status":"aborted","timestamp":1714426393085,"user_tz":240,"elapsed":4,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["#type(df_allhero[['gold_t']])"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"aBx7sVa5j5w_","executionInfo":{"status":"ok","timestamp":1714426442648,"user_tz":240,"elapsed":153,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","\n","class TimeSeriesDataset(Dataset):\n","    # Class to create our dataset\n","    def __init__(self, df, lookback):\n","        self.hero_ids = df['hero_id'].values # Declaring hero_id values\n","        self.time_series = df[['gold_t']]\n","        #[torch.tensor(ts) for ts in df['gold_t']] # Converting the time_series into Tensors\n","        self.max_length = max(len(ts) for ts in self.time_series) # Grabs max length of all the tensors to pad them with 0s later\n","        self.match_ids = df['match_id'] #Storing the match_id in case we want to view this later for more info\n","        self.lookback = lookback\n","\n","\n","    def __len__(self):\n","        return len(self.hero_ids) # Convenient length call\n","\n","\n","    def create_windows(self, timeseries, horizon):\n","        X, y = [], []\n","        for i in range(len(timeseries) - self.lookback - horizon + 1):\n","            feature = timeseries[i:i+self.lookback]\n","            target = timeseries[i:i+self.lookback+horizon] # we want the target to contain the timesteps from the lookback AND the steps forward so that the lookback steps will be treated as features\n","            X.append(feature)\n","            y.append(target)\n","\n","\n","        #print(\"Create Window X Obj:\",X)\n","        #print(\"Create Window y Obj:\",y)\n","        #print(\"Create Window Type X:\", type(X))\n","        #print(\"Create Window Type y:\", type(y))\n","        #print(len(X))\n","        #print(len(y))\n","\n","        X = torch.tensor(X)\n","        y = torch.tensor(y)\n","\n","        return X, y\n","\n","\n","\n","    def __getitem__(self, idx):\n","        #print(\"1st Step __getitem__ State: \", idx)\n","        hero_id = self.hero_ids[idx]\n","\n","        time_series = np.array(self.time_series.iloc[idx][0]).astype('float32') # Since the df_allhero 'gold_t' column is a column of lists, we take the\n","        #first row of the df_allhero with .iloc[idx]\n","        # then we access the the first element of the row, which is the list, with [0]\n","        # we convert it to a numpy array, and then convert values to float32\n","        # we do this to be compatible with the ConstantMinMaxScaler()\n","\n","        match_id = self.match_ids[idx]\n","\n","\n","\n","        scaled_time_series = ConstantMinMaxScaler(time_series, min_gold, max_gold)\n","        #print(\"Type of scaled_time_series:\",type(scaled_time_series))\n","        length = len(scaled_time_series)\n","\n","        X, y = self.create_windows(scaled_time_series, horizon = 5)\n","        #print(X.shape, y.shape)\n","        # print(\"Post create_window:\",idx)\n","        # print(\"Type of X\", type(X))\n","        # print(\"Type of y\", type(y))\n","\n","\n","\n","        return hero_id, X, y\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0ev0hr6fj5xA"},"source":["### Embedding Layer"]},{"cell_type":"markdown","metadata":{"id":"TdeRXDpij5xA"},"source":["Embedding module expects the input tensor to have a shape of (batch_size, sequence_length), where batch_size is the number of samples in a batch and sequence_length is the length of each input sequence"]},{"cell_type":"code","execution_count":111,"metadata":{"id":"J33_Gl-uj5xA","executionInfo":{"status":"ok","timestamp":1714426446864,"user_tz":240,"elapsed":260,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["class ProcessEmbedding(nn.Module):\n","    def __init__(self, df, embedding_dim, lookback):\n","        super(ProcessEmbedding, self).__init__()\n","\n","        self.num_processes = len(df['hero_id'].unique()) # declaring number of different categories of time-series for dimensionialty reasons\n","        self.embedding_dim = embedding_dim # passing our embed size to be a class attribute\n","        self.process_embeddings = nn.Embedding(self.num_processes, embedding_dim)\n","\n","        self.hero_id_to_idx = {hero_id: idx for idx, hero_id in enumerate(df['hero_id'].unique())}\n","\n","\n","\n","    def forward(self, hero_id):\n","        process_ids = self.hero_id_to_idx[hero_id]\n","        process_ids = torch.tensor([process_ids])\n","        process_embeddings = self.process_embeddings(process_ids) #.unsqueeze(1).repeat(1, self.lookback, 1)\n","\n","        # print(\"Process Embeddings shape:\", process_embeddings.shape)\n","        # print(\"Process Embeddings tensor:\", process_embeddings)\n","\n","        return process_embeddings\n"]},{"cell_type":"markdown","metadata":{"id":"oZN2kCEoj5xA"},"source":["### LSTM"]},{"cell_type":"code","execution_count":112,"metadata":{"id":"8tNlcgw0j5xA","executionInfo":{"status":"ok","timestamp":1714426449776,"user_tz":240,"elapsed":899,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size, process_embedding):\n","        super(LSTMModel, self).__init__() # ensures the correcty PyTorch class is also initialized\n","\n","        self.hidden_size = hidden_size #hyper param\n","        self.num_layers = num_layers #hyper param\n","\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True) # Actual LSTM creation\n","        self.fc = nn.Linear(hidden_size, output_size) # Linear Model creation\n","        self.process_embedding = process_embedding # Process Embedding\n","\n","\n","    def forward(self, batch):\n","        #print(\"LSTM Forward Method Batch Type: \",type(batch))\n","        # Since our Dataset class returns 3 objects, hero_id, X, y and the forward method only expects two, we have to\n","        #    tell our forward method to expect one object and unpack it\n","        hero_ids = batch[0][0] # the _ is a placeholder that doesn't save the last object in the batch which is the y tensor\n","        X = batch[1][0]\n","        X = X.unsqueeze(-1) # To match LSTM model's desired shape of (batch_size, seq_length, input_size)\n","\n","        # print(\"LSTM Forward Method X Type: \",type(X))\n","        # print(\" LSTM Forward Method - X Shape:\", X.shape)\n","        # print(\"LSTM Forward Method Tensor X\",X)\n","        # print(\"LSTM Forward Method hero_ids Type: \",type(hero_ids))\n","        # print(\"LSTM Forward Method hero_ids:\", hero_ids)\n","\n","        batch_size = X.size(0) # pulling dims from the tensor\n","        seq_length = X.size(1) # pulling dims from the tensor\n","\n","        # print(\"LSTM Forward Method - batch_size\", batch_size)\n","\n","        # Get process embeddings for hero_ids\n","        process_embeddings = self.process_embedding(hero_ids)\n","\n","        # print(\"LSTM Forward Method - Process Embeddings Shape Pre-Repeat:\", process_embeddings.shape)\n","        # print(\"LSTM Forward Method - Process Embeddings:\", process_embeddings)\n","\n","        # Reshape process embeddings to match the input shape of LSTM\n","        # process_embeddings = process_embeddings.unsqueeze(1).repeat(1, seq_length, 1)\n","        process_embeddings = process_embeddings.repeat(batch_size, seq_length, 1) # changing process embedding shape to broadcast across the same number of samples in the X tensor\n","        # we do this to match the dimensions so that torch.cat will work\n","        # print(\"LSTM Forward Method - Process Embeddings Shape Post-Repeat:\", process_embeddings.shape)\n","        # dim = -1, signifies concatenation across the last dimension (the feature dimension)\n","        combined_input = torch.cat((X,process_embeddings),dim=-1) #\n","\n","        # print(\"Concat'd Time-Series + Embedding shape:\", combined_input.shape)\n","\n","        # Unsqueexing to ensure the time_series shape is 3D like our embedding processing is so that no issues are ran into with torch.cat below\n","        #time_series = time_series.unsqueeze(-1)\n","\n","        #print(\"Time Series shape with extra dimension:\", time_series.shape)\n","\n","        # Concatenate process embeddings with time series data\n","\n","\n","\n","        # Pack the padded sequences\n","        # Packing the padded Sequences is a way of optimizing computation times. We have padded the time series to all be the same length, even though some are only 20 or less\n","        # The packing indicates which are the real values in the time series so that the computation is only ran on those time steps. Details on how are unknown to me thus far.\n","        #packed_input = pack_padded_sequence(input_data, lengths, batch_first=True, enforce_sorted=False)\n","\n","\n","        # Initialize hidden state and cell state\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","\n","\n","        #packed_output, _ = self.lstm(packed_input, (h0, c0))\n","\n","        # Unpack the output\n","        #output, _ = pad_packed_sequence(packed_output, batch_first=True)\n","\n","        # Pass combined input to LSTM layer\n","        output, _ = self.lstm(combined_input)\n","\n","        # Take the last 5 outputs of the LSTM\n","        out = self.fc(output[:, -5, :])\n","\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"upVQnTqej5xB"},"source":["### Instantiating Classes and Parameters"]},{"cell_type":"code","execution_count":121,"metadata":{"id":"xk41iRWNj5xB","executionInfo":{"status":"ok","timestamp":1714426996885,"user_tz":240,"elapsed":185,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["df2_all"]},{"cell_type":"markdown","metadata":{"id":"eFPyBntDj5xB"},"source":["### Train Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ROjpdMwTj5xB","executionInfo":{"status":"aborted","timestamp":1714426393086,"user_tz":240,"elapsed":4,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["# test_size = .30\n","\n","# train_df, test_df = train_test_split(df_full, test_size=test_size, shuffle=False)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1TXvNM6qj5xB"},"source":["#### Dataset and Data Load"]},{"cell_type":"code","execution_count":142,"metadata":{"id":"Dp4HT8Ahj5xB","executionInfo":{"status":"ok","timestamp":1714428301204,"user_tz":240,"elapsed":374,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["batch_size = 1\n","\n","lookback = 10\n","process_embedding = ProcessEmbedding(df2_allhero, embedding_dim=84, lookback=lookback) # we create the embedding vector on unsplit data to ensure all unique hero id's are contained\n","\n","input_size = process_embedding.embedding_dim + 1 #84 + 1\n","hidden_size = 64\n","num_layers = 2\n","output_size = 5  # Assuming you want to predict 5 values\n","\n","model = LSTMModel(input_size, hidden_size, num_layers, output_size, process_embedding)\n","\n","train_dataset = TimeSeriesDataset(df2_allhero, lookback=lookback)\n","test_dataset = TimeSeriesDataset(df2_all_remain, lookback=lookback)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n","# train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_dataset), batch_size=batch_size, shuffle=False)\n","# test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_dataset), batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"code","source":["df2_70_remain"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"FIuiZSdOyyHJ","executionInfo":{"status":"ok","timestamp":1714426697864,"user_tz":240,"elapsed":178,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}},"outputId":"9db33346-eb37-4879-9c00-cac1ba930876"},"execution_count":117,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        match_id  hero_id  lane  lane_role  \\\n","6924  7590862303       96   3.0        3.0   \n","6925  7590862303        6   3.0        1.0   \n","6926  7590862303       39   2.0        2.0   \n","6927  7590862303       28   1.0        3.0   \n","6928  7590862303       51   1.0        3.0   \n","...          ...      ...   ...        ...   \n","9895  7634079912       10   3.0        1.0   \n","9896  7634079912       55   1.0        3.0   \n","9897  7634079912       98   2.0        2.0   \n","9898  7634079912       45   3.0        1.0   \n","9899  7634079912       19   1.0        3.0   \n","\n","                                                 gold_t  \\\n","6924  [0, 244, 481, 727, 1156, 1246, 1468, 1797, 210...   \n","6925  [0, 164, 406, 566, 1069, 1270, 1550, 1859, 203...   \n","6926  [0, 259, 556, 1307, 1648, 2044, 2810, 3158, 35...   \n","6927  [0, 130, 483, 767, 1219, 1527, 2039, 2392, 248...   \n","6928  [0, 130, 220, 310, 600, 690, 921, 1146, 1236, ...   \n","...                                                 ...   \n","9895  [0, 245, 553, 935, 1262, 1593, 2021, 2489, 295...   \n","9896  [0, 209, 445, 744, 1168, 1593, 1953, 2531, 275...   \n","9897  [0, 332, 654, 1046, 1536, 1828, 2285, 3071, 35...   \n","9898  [0, 209, 299, 469, 589, 789, 971, 1186, 1392, ...   \n","9899  [0, 312, 402, 604, 770, 1163, 1298, 1668, 1843...   \n","\n","               radiant_team             dire_team  radiant_win  \n","6924  [95, 26, 13, 100, 96]   [6, 39, 28, 51, 20]         True  \n","6925  [95, 26, 13, 100, 96]   [6, 39, 28, 51, 20]        False  \n","6926  [95, 26, 13, 100, 96]   [6, 39, 28, 51, 20]        False  \n","6927  [95, 26, 13, 100, 96]   [6, 39, 28, 51, 20]        False  \n","6928  [95, 26, 13, 100, 96]   [6, 39, 28, 51, 20]        False  \n","...                     ...                   ...          ...  \n","9895   [74, 94, 105, 5, 38]  [10, 55, 98, 45, 19]         True  \n","9896   [74, 94, 105, 5, 38]  [10, 55, 98, 45, 19]         True  \n","9897   [74, 94, 105, 5, 38]  [10, 55, 98, 45, 19]         True  \n","9898   [74, 94, 105, 5, 38]  [10, 55, 98, 45, 19]         True  \n","9899   [74, 94, 105, 5, 38]  [10, 55, 98, 45, 19]         True  \n","\n","[2976 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-ba929763-0ab3-460f-bdab-f0817ffaa5f0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>match_id</th>\n","      <th>hero_id</th>\n","      <th>lane</th>\n","      <th>lane_role</th>\n","      <th>gold_t</th>\n","      <th>radiant_team</th>\n","      <th>dire_team</th>\n","      <th>radiant_win</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6924</th>\n","      <td>7590862303</td>\n","      <td>96</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>[0, 244, 481, 727, 1156, 1246, 1468, 1797, 210...</td>\n","      <td>[95, 26, 13, 100, 96]</td>\n","      <td>[6, 39, 28, 51, 20]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>6925</th>\n","      <td>7590862303</td>\n","      <td>6</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>[0, 164, 406, 566, 1069, 1270, 1550, 1859, 203...</td>\n","      <td>[95, 26, 13, 100, 96]</td>\n","      <td>[6, 39, 28, 51, 20]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>6926</th>\n","      <td>7590862303</td>\n","      <td>39</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>[0, 259, 556, 1307, 1648, 2044, 2810, 3158, 35...</td>\n","      <td>[95, 26, 13, 100, 96]</td>\n","      <td>[6, 39, 28, 51, 20]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>6927</th>\n","      <td>7590862303</td>\n","      <td>28</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>[0, 130, 483, 767, 1219, 1527, 2039, 2392, 248...</td>\n","      <td>[95, 26, 13, 100, 96]</td>\n","      <td>[6, 39, 28, 51, 20]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>6928</th>\n","      <td>7590862303</td>\n","      <td>51</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>[0, 130, 220, 310, 600, 690, 921, 1146, 1236, ...</td>\n","      <td>[95, 26, 13, 100, 96]</td>\n","      <td>[6, 39, 28, 51, 20]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9895</th>\n","      <td>7634079912</td>\n","      <td>10</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>[0, 245, 553, 935, 1262, 1593, 2021, 2489, 295...</td>\n","      <td>[74, 94, 105, 5, 38]</td>\n","      <td>[10, 55, 98, 45, 19]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>9896</th>\n","      <td>7634079912</td>\n","      <td>55</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>[0, 209, 445, 744, 1168, 1593, 1953, 2531, 275...</td>\n","      <td>[74, 94, 105, 5, 38]</td>\n","      <td>[10, 55, 98, 45, 19]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>9897</th>\n","      <td>7634079912</td>\n","      <td>98</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>[0, 332, 654, 1046, 1536, 1828, 2285, 3071, 35...</td>\n","      <td>[74, 94, 105, 5, 38]</td>\n","      <td>[10, 55, 98, 45, 19]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>9898</th>\n","      <td>7634079912</td>\n","      <td>45</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>[0, 209, 299, 469, 589, 789, 971, 1186, 1392, ...</td>\n","      <td>[74, 94, 105, 5, 38]</td>\n","      <td>[10, 55, 98, 45, 19]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>9899</th>\n","      <td>7634079912</td>\n","      <td>19</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>[0, 312, 402, 604, 770, 1163, 1298, 1668, 1843...</td>\n","      <td>[74, 94, 105, 5, 38]</td>\n","      <td>[10, 55, 98, 45, 19]</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2976 rows × 8 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba929763-0ab3-460f-bdab-f0817ffaa5f0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ba929763-0ab3-460f-bdab-f0817ffaa5f0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ba929763-0ab3-460f-bdab-f0817ffaa5f0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ab2140c4-04d3-4c83-a4bb-8a94ba8664eb\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab2140c4-04d3-4c83-a4bb-8a94ba8664eb')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ab2140c4-04d3-4c83-a4bb-8a94ba8664eb button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_f227af04-99b0-432b-b710-9195a9480a4d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2_70_remain')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f227af04-99b0-432b-b710-9195a9480a4d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df2_70_remain');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df2_70_remain","summary":"{\n  \"name\": \"df2_70_remain\",\n  \"rows\": 2976,\n  \"fields\": [\n    {\n      \"column\": \"match_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12245977,\n        \"min\": 7590862303,\n        \"max\": 7634079912,\n        \"num_unique_values\": 298,\n        \"samples\": [\n          7613240917,\n          7631492612,\n          7630006507\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hero_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39,\n        \"min\": 1,\n        \"max\": 138,\n        \"num_unique_values\": 124,\n        \"samples\": [\n          102,\n          23,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lane\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.890648737178107,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2.0,\n          5.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lane_role\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8897140575396171,\n        \"min\": 1.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0,\n          4.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gold_t\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"radiant_team\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dire_team\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"radiant_win\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":117}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OL22AP1zj5xB","executionInfo":{"status":"aborted","timestamp":1714426393086,"user_tz":240,"elapsed":3,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["#len(df_allhero.iloc[32]['gold_t'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1Pel3NFj5xB","executionInfo":{"status":"aborted","timestamp":1714426393086,"user_tz":240,"elapsed":3,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"outputs":[],"source":["# # Iterate over the train_loader until the desired index\n","# for idx, (hero_ids, X, y) in enumerate(train_loader):\n","#     print(idx)\n","#     if idx == 32:\n","#         print('Gottem')\n","#         break"]},{"cell_type":"code","execution_count":143,"metadata":{"id":"bAO_dcHej5xB","colab":{"base_uri":"https://localhost:8080/","height":515},"executionInfo":{"status":"error","timestamp":1714428312339,"user_tz":240,"elapsed":2468,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}},"outputId":"542b2e24-ca0b-4949-b0eb-87945f88ec2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0\n"]},{"output_type":"error","ename":"KeyError","evalue":"90","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 90","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-143-e20e5d6c6919>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m          \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#for hero_ids, X, y in test_loader:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;31m#print(\"Batch in Test_Loader: \", batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-131-274dccb777c7>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# we do this to be compatible with the ConstantMinMaxScaler()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mmatch_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 90"]}],"source":["# Training loop\n","num_epochs = 500\n","\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","best_test_loss = float('inf')\n","best_model_state = None\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","\n","    train_loss = 0.0\n","    print(f\"Epoch: {epoch}\")\n","\n","    for batch in train_loader: #for hero_ids, X, y in train_loader:\n","\n","        hero_ids, X, y = batch #outputs = model(hero_ids, X)\n","        #print(\"Training Loop X Type\", type(X))\n","        #print(\"Training Loop X shape\", len(X))\n","        #print(\"Training Loop X\", X)\n","\n","        #print(\"Training Loop Heros Type\", type(hero_ids))\n","        #print(\"Training Loop Heros shape\", len(hero_ids))\n","        #print(\"Training Loop Heros\", hero_ids)\n","\n","        X = X[0]\n","        # print(\"Training Loop X Type\", type(X))\n","        #print(\"Training Loop X shape\", X.size())\n","        # print(\"Training Loop X\", X)\n","\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(batch)\n","        #print(\"Model Outputs: \", outputs)\n","        #print(\"Model Outputs Size: \", outputs.size())\n","\n","        y = y[0]\n","        # print(\"Training Loop Y Type\", type(y))\n","        #print(\"Training Loop Y shape\", y.size())\n","        #print(\"Training Loop Y\", y)\n","\n","        targets = y[:, -5:]  # Assuming you want to predict the last value of each time series\n","        # Maybe should be 5\n","        #print(\"targets last 5 size: \", targets.size())\n","        #print(\"targets last 5: \", targets)\n","        loss = criterion(outputs.squeeze(), targets.squeeze())\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item() * X.size(0)\n","\n","    train_loss /= len(train_dataset)\n","\n","    model.eval()\n","    test_loss = 0.0\n","\n","    with torch.no_grad():\n","         for batch in test_loader: #for hero_ids, X, y in test_loader:\n","            #print(\"Batch in Test_Loader: \", batch)\n","            # Forward pass\n","            hero_ids, X, y = batch\n","            X = X[0]\n","            y = y[0]\n","            outputs = model(batch) # outputs = model(hero_ids, X)\n","            targets = y[:, -5:]  # Assuming you want to predict the last value of each time series\n","            loss = criterion(outputs.squeeze(), targets.squeeze())\n","\n","            test_loss += loss.item() * X.size(0)\n","\n","    test_loss /= len(test_dataset)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n","\n","    if test_loss < best_test_loss:\n","      best_test_loss = test_loss\n","      best_model_state = model.state_dict()\n","\n","torch.save(best_model_state, '10step_5horizon_best_model.pth')\n","print(best_test_loss)"]},{"cell_type":"markdown","source":["### Loading Data and Model from Saved Points"],"metadata":{"id":"IjtywPhGW_Ga"}},{"cell_type":"code","source":[],"metadata":{"id":"JEHwRHNeS8Sn","executionInfo":{"status":"aborted","timestamp":1714426393089,"user_tz":240,"elapsed":2568,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Fx00UJz-ISKU","executionInfo":{"status":"aborted","timestamp":1714426393233,"user_tz":240,"elapsed":2,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}