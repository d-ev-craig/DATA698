{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPWBhPk/Eew8Q3/TAyyBrDx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4-jxrjuZ_Uhb"},"outputs":[],"source":["import json\n","import pandas as pd\n","from numpy import array\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Used in LTSMModel Class Instantiation\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","source":[],"metadata":{"id":"iSzXVtJh_ipI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBx7sVa5j5w_"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","\n","class TimeSeriesDataset(Dataset):\n","    # Class to create our dataset\n","    def __init__(self, df, lookback):\n","        self.hero_ids = df['hero_id'].values # Declaring hero_id values\n","        self.time_series = df[['gold_t']]\n","        #[torch.tensor(ts) for ts in df['gold_t']] # Converting the time_series into Tensors\n","        self.max_length = max(len(ts) for ts in self.time_series) # Grabs max length of all the tensors to pad them with 0s later\n","        self.match_ids = df['match_id'] #Storing the match_id in case we want to view this later for more info\n","        self.lookback = lookback\n","\n","\n","    def __len__(self):\n","        return len(self.hero_ids) # Convenient length call\n","\n","\n","    def create_windows(self, timeseries, horizon):\n","        X, y = [], []\n","        for i in range(len(timeseries) - self.lookback - horizon + 1):\n","            feature = timeseries[i:i+self.lookback]\n","            target = timeseries[i:i+self.lookback+horizon] # we want the target to contain the timesteps from the lookback AND the steps forward so that the lookback steps will be treated as features\n","            X.append(feature)\n","            y.append(target)\n","\n","\n","        #print(\"Create Window X Obj:\",X)\n","        #print(\"Create Window y Obj:\",y)\n","        #print(\"Create Window Type X:\", type(X))\n","        #print(\"Create Window Type y:\", type(y))\n","        #print(len(X))\n","        #print(len(y))\n","\n","        X = torch.tensor(X)\n","        y = torch.tensor(y)\n","\n","        return X, y\n","\n","\n","\n","    def __getitem__(self, idx):\n","        #print(\"1st Step __getitem__ State: \", idx)\n","        hero_id = self.hero_ids[idx]\n","\n","        time_series = np.array(self.time_series.iloc[idx][0]).astype('float32') # Since the df_allhero 'gold_t' column is a column of lists, we take the\n","        #first row of the df_allhero with .iloc[idx]\n","        # then we access the the first element of the row, which is the list, with [0]\n","        # we convert it to a numpy array, and then convert values to float32\n","        # we do this to be compatible with the ConstantMinMaxScaler()\n","\n","        match_id = self.match_ids[idx]\n","\n","\n","\n","        scaled_time_series = ConstantMinMaxScaler(time_series, min_gold, max_gold)\n","        #print(\"Type of scaled_time_series:\",type(scaled_time_series))\n","        length = len(scaled_time_series)\n","\n","        X, y = self.create_windows(scaled_time_series, horizon = 5)\n","        #print(X.shape, y.shape)\n","        # print(\"Post create_window:\",idx)\n","        # print(\"Type of X\", type(X))\n","        # print(\"Type of y\", type(y))\n","\n","\n","\n","        return hero_id, X, y\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J33_Gl-uj5xA"},"outputs":[],"source":["class ProcessEmbedding(nn.Module):\n","    def __init__(self, df, embedding_dim, lookback):\n","        super(ProcessEmbedding, self).__init__()\n","\n","        self.num_processes = len(df['hero_id'].unique()) # declaring number of different categories of time-series for dimensionialty reasons\n","        self.embedding_dim = embedding_dim # passing our embed size to be a class attribute\n","        self.process_embeddings = nn.Embedding(self.num_processes, embedding_dim)\n","\n","        self.hero_id_to_idx = {hero_id: idx for idx, hero_id in enumerate(df['hero_id'].unique())}\n","\n","\n","\n","    def forward(self, hero_id):\n","        process_ids = self.hero_id_to_idx[hero_id]\n","        process_ids = torch.tensor([process_ids])\n","        process_embeddings = self.process_embeddings(process_ids) #.unsqueeze(1).repeat(1, self.lookback, 1)\n","\n","        # print(\"Process Embeddings shape:\", process_embeddings.shape)\n","        # print(\"Process Embeddings tensor:\", process_embeddings)\n","\n","        return process_embeddings\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8tNlcgw0j5xA"},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size, process_embedding):\n","        super(LSTMModel, self).__init__() # ensures the correcty PyTorch class is also initialized\n","\n","        self.hidden_size = hidden_size #hyper param\n","        self.num_layers = num_layers #hyper param\n","\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True) # Actual LSTM creation\n","        self.fc = nn.Linear(hidden_size, output_size) # Linear Model creation\n","        self.process_embedding = process_embedding # Process Embedding\n","\n","\n","    def forward(self, batch):\n","        #print(\"LSTM Forward Method Batch Type: \",type(batch))\n","        # Since our Dataset class returns 3 objects, hero_id, X, y and the forward method only expects two, we have to\n","        #    tell our forward method to expect one object and unpack it\n","        hero_ids = batch[0][0] # the _ is a placeholder that doesn't save the last object in the batch which is the y tensor\n","        X = batch[1][0]\n","        X = X.unsqueeze(-1) # To match LSTM model's desired shape of (batch_size, seq_length, input_size)\n","\n","        # print(\"LSTM Forward Method X Type: \",type(X))\n","        # print(\" LSTM Forward Method - X Shape:\", X.shape)\n","        # print(\"LSTM Forward Method Tensor X\",X)\n","        # print(\"LSTM Forward Method hero_ids Type: \",type(hero_ids))\n","        # print(\"LSTM Forward Method hero_ids:\", hero_ids)\n","\n","        batch_size = X.size(0) # pulling dims from the tensor\n","        seq_length = X.size(1) # pulling dims from the tensor\n","\n","        # print(\"LSTM Forward Method - batch_size\", batch_size)\n","\n","        # Get process embeddings for hero_ids\n","        process_embeddings = self.process_embedding(hero_ids)\n","\n","        # print(\"LSTM Forward Method - Process Embeddings Shape Pre-Repeat:\", process_embeddings.shape)\n","        # print(\"LSTM Forward Method - Process Embeddings:\", process_embeddings)\n","\n","        # Reshape process embeddings to match the input shape of LSTM\n","        # process_embeddings = process_embeddings.unsqueeze(1).repeat(1, seq_length, 1)\n","        process_embeddings = process_embeddings.repeat(batch_size, seq_length, 1) # changing process embedding shape to broadcast across the same number of samples in the X tensor\n","        # we do this to match the dimensions so that torch.cat will work\n","        # print(\"LSTM Forward Method - Process Embeddings Shape Post-Repeat:\", process_embeddings.shape)\n","        # dim = -1, signifies concatenation across the last dimension (the feature dimension)\n","        combined_input = torch.cat((X,process_embeddings),dim=-1) #\n","\n","        # print(\"Concat'd Time-Series + Embedding shape:\", combined_input.shape)\n","\n","        # Unsqueexing to ensure the time_series shape is 3D like our embedding processing is so that no issues are ran into with torch.cat below\n","        #time_series = time_series.unsqueeze(-1)\n","\n","        #print(\"Time Series shape with extra dimension:\", time_series.shape)\n","\n","        # Concatenate process embeddings with time series data\n","\n","\n","\n","        # Pack the padded sequences\n","        # Packing the padded Sequences is a way of optimizing computation times. We have padded the time series to all be the same length, even though some are only 20 or less\n","        # The packing indicates which are the real values in the time series so that the computation is only ran on those time steps. Details on how are unknown to me thus far.\n","        #packed_input = pack_padded_sequence(input_data, lengths, batch_first=True, enforce_sorted=False)\n","\n","\n","        # Initialize hidden state and cell state\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","\n","\n","        #packed_output, _ = self.lstm(packed_input, (h0, c0))\n","\n","        # Unpack the output\n","        #output, _ = pad_packed_sequence(packed_output, batch_first=True)\n","\n","        # Pass combined input to LSTM layer\n","        output, _ = self.lstm(combined_input)\n","\n","        # Take the last 5 outputs of the LSTM\n","        out = self.fc(output[:, -5, :])\n","\n","        return out"]}]}