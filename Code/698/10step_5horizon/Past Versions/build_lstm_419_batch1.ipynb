{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dx-wxtGvj5w7"},"outputs":[],"source":["import json\n","import pandas as pd\n","from numpy import array\n","\n","import torch\n","import torch.nn\n","import torch.optim as optim\n","\n","# Used in LTSMModel Class Instantiation\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDlqrOEAkcLO","executionInfo":{"status":"ok","timestamp":1714009652737,"user_tz":240,"elapsed":1287,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}},"outputId":"1ed766f7-da7e-48d3-e456-36faddd9b2a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/698/data/10step_1horizon\")"],"metadata":{"id":"3N75xrN6kc8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3s39p0k_j5w9","executionInfo":{"status":"error","timestamp":1714009661382,"user_tz":240,"elapsed":8648,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}},"outputId":"8281a258-8032-4be9-b471-a073b7f1a435"},"outputs":[{"output_type":"stream","name":"stdout","text":["      hero_id gold_t\n","2270       20   None\n","2271      120   None\n","2272       69   None\n","2273       73   None\n","2274       26   None\n","...       ...    ...\n","6915      136   None\n","6916      106   None\n","6917      137   None\n","6918       14   None\n","6919      112   None\n","\n","[76 rows x 2 columns]\n","      hero_id gold_t\n","2270       20   None\n","2271      120   None\n","2272       69   None\n","2273       73   None\n","2274       26   None\n","...       ...    ...\n","6915      136   None\n","6916      106   None\n","6917      137   None\n","6918       14   None\n","6919      112   None\n","\n","[76 rows x 2 columns]\n","Found 34 tensors with length 0 at indices: [810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 2460, 2501, 2512, 2583, 5414, 5415, 5416, 5417, 5418, 5419, 5420, 5421, 5422, 5423]\n","Found 34 tensors with length 0 at indices: [810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 2460, 2501, 2512, 2583, 5414, 5415, 5416, 5417, 5418, 5419, 5420, 5421, 5422, 5423]\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'X_scaled' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/698/data_prep_one_hero.ipynb\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X_scaled' is not defined"]},{"output_type":"error","ename":"NameError","evalue":"name 'X_scaled' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-d1de1b350ba6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_prep_one_hero.ipynb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-52>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mpreserve_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__file__'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_execfile_ipy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msafe_execfile_ipy\u001b[0;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[1;32m   2903\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell_futures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell_futures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mraise_exceptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2905\u001b[0;31m                         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2906\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mraise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-13-3b16f12bd7c7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X_scaled' is not defined"]}],"source":["#%run data_prep_one_hero.ipynb\n","\n","#torch.load(df_allhero, 'df_allhero.pt')\n","#torch.load(hero_ids, 'hero_ids.pt')\n","#torch.load(df_all_remain, 'df_all_remain.pt')\n","\n","torch.load(df2_allhero, 'df2_allhero.pt')\n","torch.load(hero_ids2, 'hero_ids2.pt')\n","torch.load(df2_all_remain, 'df2_all_remain.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"865_J5kUj5w9"},"outputs":[],"source":["#df_allhero[['gold_t']]\n","\n","#df_allhero[['gold_t']] ="]},{"cell_type":"code","source":["df2_allhero_avglen"],"metadata":{"id":"xAkelUZRXnsG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWSC-SpZj5w-"},"outputs":[],"source":["len(df_allhero.iloc[0]['gold_t'])"]},{"cell_type":"markdown","metadata":{"id":"S2LbZpekj5w-"},"source":["### TimeSeriesDataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LyuKx4qj5w_"},"outputs":[],"source":["type(df_allhero[['gold_t']])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBx7sVa5j5w_"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","\n","class TimeSeriesDataset(Dataset):\n","    # Class to create our dataset\n","    def __init__(self, df, lookback):\n","        self.hero_ids = df['hero_id'].values # Declaring hero_id values\n","        self.time_series = df[['gold_t']]\n","        #[torch.tensor(ts) for ts in df['gold_t']] # Converting the time_series into Tensors\n","        self.max_length = max(len(ts) for ts in self.time_series) # Grabs max length of all the tensors to pad them with 0s later\n","        self.match_ids = df['match_id'] #Storing the match_id in case we want to view this later for more info\n","        self.lookback = lookback\n","\n","\n","    def __len__(self):\n","        return len(self.hero_ids) # Convenient length call\n","\n","\n","    def create_windows(self, timeseries):\n","        X, y = [], []\n","        for i in range(len(timeseries) - self.lookback):\n","            feature = timeseries[i:i+self.lookback]\n","            target = timeseries[i+1:i+self.lookback+1]\n","            X.append(feature)\n","            y.append(target)\n","\n","\n","        # print(\"Create Window X Obj:\",X)\n","        # print(\"Create Window y Obj:\",y)\n","        # print(\"Create Window Type X:\", type(X))\n","        # print(\"Create Window Type y:\", type(y))\n","        #print(len(X))\n","        #print(len(y))\n","\n","        X = torch.tensor(X)\n","        y = torch.tensor(y)\n","        return X, y\n","\n","\n","\n","    def __getitem__(self, idx):\n","        #print(\"1st Step __getitem__ State: \", idx)\n","        hero_id = self.hero_ids[idx]\n","\n","        time_series = np.array(self.time_series.iloc[idx][0]).astype('float32') # Since the df_allhero 'gold_t' column is a column of lists, we take the\n","        #first row of the df_allhero with .iloc[idx]\n","        # then we access the the first element of the row, which is the list, with [0]\n","        # we convert it to a numpy array, and then convert values to float32\n","        # we do this to be compatible with the ConstantMinMaxScaler()\n","\n","        match_id = self.match_ids[idx]\n","\n","\n","\n","        scaled_time_series = ConstantMinMaxScaler(time_series, min_gold, max_gold)\n","        #print(\"Type of scaled_time_series:\",type(scaled_time_series))\n","        length = len(scaled_time_series)\n","\n","        X, y = self.create_windows(scaled_time_series)\n","        #print(X.shape, y.shape)\n","        # print(\"Post create_window:\",idx)\n","        # print(\"Type of X\", type(X))\n","        # print(\"Type of y\", type(y))\n","\n","\n","\n","        return hero_id, X, y\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0ev0hr6fj5xA"},"source":["### Embedding Layer"]},{"cell_type":"markdown","metadata":{"id":"TdeRXDpij5xA"},"source":["Embedding module expects the input tensor to have a shape of (batch_size, sequence_length), where batch_size is the number of samples in a batch and sequence_length is the length of each input sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J33_Gl-uj5xA"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class ProcessEmbedding(nn.Module):\n","    def __init__(self, df, embedding_dim, lookback):\n","        super(ProcessEmbedding, self).__init__()\n","\n","        self.num_processes = len(df['hero_id'].unique()) # declaring number of different categories of time-series for dimensionialty reasons\n","        self.embedding_dim = embedding_dim # passing our embed size to be a class attribute\n","        self.process_embeddings = nn.Embedding(self.num_processes, embedding_dim)\n","\n","        self.hero_id_to_idx = {hero_id: idx for idx, hero_id in enumerate(df['hero_id'].unique())}\n","\n","\n","\n","    def forward(self, hero_id):\n","        process_ids = self.hero_id_to_idx[hero_id]\n","        process_ids = torch.tensor([process_ids])\n","        process_embeddings = self.process_embeddings(process_ids) #.unsqueeze(1).repeat(1, self.lookback, 1)\n","\n","        # print(\"Process Embeddings shape:\", process_embeddings.shape)\n","        # print(\"Process Embeddings tensor:\", process_embeddings)\n","\n","        return process_embeddings\n"]},{"cell_type":"markdown","metadata":{"id":"oZN2kCEoj5xA"},"source":["### LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8tNlcgw0j5xA"},"outputs":[],"source":["class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size, process_embedding):\n","        super(LSTMModel, self).__init__() # ensures the correcty PyTorch class is also initialized\n","\n","        self.hidden_size = hidden_size #hyper param\n","        self.num_layers = num_layers #hyper param\n","\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True) # Actual LSTM creation\n","        self.fc = nn.Linear(hidden_size, output_size) # Linear Model creation\n","        self.process_embedding = process_embedding # Process Embedding\n","\n","\n","    def forward(self, batch):\n","        #print(\"LSTM Forward Method Batch Type: \",type(batch))\n","        # Since our Dataset class returns 3 objects, hero_id, X, y and the forward method only expects two, we have to\n","        #    tell our forward method to expect one object and unpack it\n","        hero_ids = batch[0][0] # the _ is a placeholder that doesn't save the last object in the batch which is the y tensor\n","        X = batch[1][0]\n","        X = X.unsqueeze(-1) # To match LSTM model's desired shape of (batch_size, seq_length, input_size)\n","\n","        # print(\"LSTM Forward Method X Type: \",type(X))\n","        # print(\" LSTM Forward Method - X Shape:\", X.shape)\n","        # print(\"LSTM Forward Method Tensor X\",X)\n","        # print(\"LSTM Forward Method hero_ids Type: \",type(hero_ids))\n","        # print(\"LSTM Forward Method hero_ids:\", hero_ids)\n","\n","        batch_size = X.size(0) # pulling dims from the tensor\n","        seq_length = X.size(1) # pulling dims from the tensor\n","\n","        # print(\"LSTM Forward Method - batch_size\", batch_size)\n","\n","        # Get process embeddings for hero_ids\n","        process_embeddings = self.process_embedding(hero_ids)\n","\n","        # print(\"LSTM Forward Method - Process Embeddings Shape Pre-Repeat:\", process_embeddings.shape)\n","        # print(\"LSTM Forward Method - Process Embeddings:\", process_embeddings)\n","\n","        # Reshape process embeddings to match the input shape of LSTM\n","        # process_embeddings = process_embeddings.unsqueeze(1).repeat(1, seq_length, 1)\n","        process_embeddings = process_embeddings.repeat(batch_size, seq_length, 1) # changing process embedding shape to broadcast across the same number of samples in the X tensor\n","        # we do this to match the dimensions so that torch.cat will work\n","        # print(\"LSTM Forward Method - Process Embeddings Shape Post-Repeat:\", process_embeddings.shape)\n","        # dim = -1, signifies concatenation across the last dimension (the feature dimension)\n","        combined_input = torch.cat((X,process_embeddings),dim=-1) #\n","\n","        # print(\"Concat'd Time-Series + Embedding shape:\", combined_input.shape)\n","\n","        # Unsqueexing to ensure the time_series shape is 3D like our embedding processing is so that no issues are ran into with torch.cat below\n","        #time_series = time_series.unsqueeze(-1)\n","\n","        #print(\"Time Series shape with extra dimension:\", time_series.shape)\n","\n","        # Concatenate process embeddings with time series data\n","\n","\n","\n","        # Pack the padded sequences\n","        # Packing the padded Sequences is a way of optimizing computation times. We have padded the time series to all be the same length, even though some are only 20 or less\n","        # The packing indicates which are the real values in the time series so that the computation is only ran on those time steps. Details on how are unknown to me thus far.\n","        #packed_input = pack_padded_sequence(input_data, lengths, batch_first=True, enforce_sorted=False)\n","\n","\n","        # Initialize hidden state and cell state\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","\n","\n","        #packed_output, _ = self.lstm(packed_input, (h0, c0))\n","\n","        # Unpack the output\n","        #output, _ = pad_packed_sequence(packed_output, batch_first=True)\n","\n","        # Pass combined input to LSTM layer\n","        output, _ = self.lstm(combined_input)\n","\n","        # Take the last output of the LSTM\n","        out = self.fc(output[:, -1, :])\n","\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"upVQnTqej5xB"},"source":["### Instantiating Classes and Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xk41iRWNj5xB"},"outputs":[],"source":["lookback = 10\n","#train_dataset = TimeSeriesDataset(df_allhero, lookback)\n","process_embedding = ProcessEmbedding(df2_allhero, embedding_dim=84, lookback=lookback) # we create the embedding vector on unsplit data to ensure all unique hero id's are contained\n","\n","input_size = process_embedding.embedding_dim + 1 #84 + 1\n","hidden_size = 64\n","num_layers = 2\n","output_size = 1  # Assuming you want to predict a single value\n","\n","model = LSTMModel(input_size, hidden_size, num_layers, output_size, process_embedding)"]},{"cell_type":"markdown","metadata":{"id":"eFPyBntDj5xB"},"source":["### Train Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ROjpdMwTj5xB"},"outputs":[],"source":["# test_size = .30\n","\n","# train_df, test_df = train_test_split(df_full, test_size=test_size, shuffle=False)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1TXvNM6qj5xB"},"source":["#### Dataset and Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dp4HT8Ahj5xB"},"outputs":[],"source":["batch_size = 1\n","\n","train_dataset = TimeSeriesDataset(df2_allhero, lookback=lookback)\n","test_dataset = TimeSeriesDataset(df2_allhero_avglen, lookback=lookback)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n","# train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_dataset), batch_size=batch_size, shuffle=False)\n","# test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_dataset), batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OL22AP1zj5xB"},"outputs":[],"source":["#len(df_allhero.iloc[32]['gold_t'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1Pel3NFj5xB"},"outputs":[],"source":["# # Iterate over the train_loader until the desired index\n","# for idx, (hero_ids, X, y) in enumerate(train_loader):\n","#     print(idx)\n","#     if idx == 32:\n","#         print('Gottem')\n","#         break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bAO_dcHej5xB"},"outputs":[],"source":["# Training loop\n","num_epochs = 500\n","\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","best_test_loss = float('inf')\n","best_model_state = None\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","\n","    train_loss = 0.0\n","    print(f\"Epoch: {epoch}\")\n","\n","    for batch in train_loader: #for hero_ids, X, y in train_loader:\n","\n","        hero_ids, X, y = batch #outputs = model(hero_ids, X)\n","        #print(\"Training Loop X Type\", type(X))\n","        #print(\"Training Loop X shape\", len(X))\n","        #print(\"Training Loop X\", X)\n","\n","        #print(\"Training Loop Heros Type\", type(hero_ids))\n","        #print(\"Training Loop Heros shape\", len(hero_ids))\n","        #print(\"Training Loop Heros\", hero_ids)\n","\n","        X = X[0]\n","        # print(\"Training Loop X Type\", type(X))\n","        # print(\"Training Loop X shape\", len(X))\n","        # print(\"Training Loop X\", X)\n","\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(batch)\n","\n","        y = y[0]\n","        # print(\"Training Loop Y Type\", type(y))\n","        # print(\"Training Loop Y shape\", len(y))\n","        # print(\"Training Loop Y\", y)\n","\n","        targets = y[:, -1]  # Assuming you want to predict the last value of each time series\n","        loss = criterion(outputs.squeeze(), targets.squeeze())\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item() * X.size(0)\n","\n","    train_loss /= len(train_dataset)\n","\n","    model.eval()\n","    test_loss = 0.0\n","\n","    with torch.no_grad():\n","         for batch in test_loader: #for hero_ids, X, y in test_loader:\n","            # Forward pass\n","            hero_ids, X, y = batch\n","            X = X[0]\n","            y = y[0]\n","            outputs = model(batch) # outputs = model(hero_ids, X)\n","            targets = y[:, -1]  # Assuming you want to predict the last value of each time series\n","            loss = criterion(outputs.squeeze(), targets.squeeze())\n","\n","            test_loss += loss.item() * X.size(0)\n","\n","    test_loss /= len(test_dataset)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n","\n","    if test_loss < best_test_loss:\n","      best_test_loss = test_loss\n","      best_model_state = model.state_dict()\n","\n","torch.save(best_model_state, '10step_1horizon_best_model.pth')"]},{"cell_type":"code","source":["best_model_state = torch.load('10step_1horizon_best_model.pth')\n"],"metadata":{"id":"Be8MiuFYCY0h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_windows(timeseries, lookback):\n","    X, y = [], []\n","    for i in range(len(timeseries) - lookback):\n","        feature = timeseries[i:i+lookback]\n","        target = timeseries[i+1:i+lookback+1]\n","        X.append(feature)\n","        y.append(target)\n","\n","    X = torch.tensor(X)\n","    y = torch.tensor(y)\n","    return X, y"],"metadata":{"id":"t9W9Llj-w8sY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming you have already trained the model and have the `model` object available\n","model.load_state_dict(best_model_state)\n","# Select a specific time series from df_all_remain\n","index = 8000  # Choose the index of the desired time series\n","selected_row = df_all_remain.iloc[index]\n","\n","# Extract the necessary information from the selected row\n","hero_id = selected_row['hero_id']\n","time_series = np.array(selected_row['gold_t']).astype('float32')\n","\n","# Scale the time series using the same scaling function used during training\n","scaled_time_series = ConstantMinMaxScaler(time_series, min_gold, max_gold)\n","\n","# Create windows from the scaled time series\n","X, y = create_windows(scaled_time_series, lookback)\n","\n","# Convert X and y to tensors\n","#X = torch.tensor(X)\n","#y = torch.tensor(y)\n","\n","# Create a batch with the selected time series\n","batch = ((hero_id,), (X,), (y,))\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","# Disable gradient computation\n","with torch.no_grad():\n","    # Forward pass\n","    outputs = model(batch)\n","\n","    # Get the predicted values\n","    predicted = outputs.squeeze().numpy()\n","\n","\n","#Unscaling values\n","unscaled_targets = ConstantUnScaler(y[:,-1], min_gold, max_gold)\n","unscaled_preds = ConstantUnScaler(predicted, min_gold, max_gold)\n","\n","# Print the predicted values\n","print(\"Targets:\")\n","print(y[:,-1])\n","print(\"Predicted values:\")\n","print(predicted)\n","\n","# Print Unscaled Targets\n","print(\"Unscaled Targets\")\n","print(unscaled_targets)\n","print(\"Unscaled Preds\")\n","print(unscaled_preds)"],"metadata":{"id":"H1tdmZASvsXf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","preds_plot = np.ones_like(time_series) * np.nan\n","preds_plot[lookback:lookback+len(unscaled_preds)] = unscaled_preds\n","# plot\n","plt.plot(time_series, label = \"Actual Values\")\n","plt.plot(preds_plot, c='r', label = \"Forecasting Predictions\")\n","#plt.plot(test_plot, c='g', label = \"Test Predictions\")\n","\n","plt.title(f\"HeroID:{hero_id} Game Length: {len(time_series)} Minutes, Lookback Window: {lookback}\")\n","\n","# Add a label to the x-axis\n","plt.xlabel('Timestep (Minute)')\n","\n","# Add a label to the y-axis\n","plt.ylabel('Gold')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"sWXrFIV2ysAe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Fx00UJz-ISKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qWLdXYfbj5xC"},"outputs":[],"source":["import pandas as pd\n","from sklearn.metrics import mean_squared_error\n","\n","# Create an empty dataframe to store the average RMSE scores for each hero\n","df_results_all = pd.DataFrame(columns=['hero_id', 'avg_rmse'])\n","\n","# Get the unique hero_ids from the dataframe\n","hero_ids = df_all_remain['hero_id'].unique()\n","\n","# Loop over each hero_id\n","for hero_id in hero_ids:\n","    # Filter the dataframe for the current hero_id\n","    hero_df = df_all_remain[df_all_remain['hero_id'] == hero_id]\n","\n","    # Create empty lists to store the unscaled targets and predictions for the current hero\n","    unscaled_targets_list = []\n","    unscaled_preds_list = []\n","\n","    # Loop over each record for the current hero\n","    for index, row in hero_df.iterrows():\n","        # Extract the necessary information from the row\n","        time_series = np.array(row['gold_t']).astype('float32')\n","\n","        # Scale the time series using the same scaling function used during training\n","        scaled_time_series = ConstantMinMaxScaler(time_series, min_gold, max_gold)\n","\n","        # Create windows from the scaled time series\n","        X, y = create_windows(scaled_time_series, lookback)\n","\n","        # Create a batch with the selected time series\n","        batch = ((hero_id,), (X,), (y,))\n","\n","        # Set the model to evaluation mode\n","        model.eval()\n","\n","        # Disable gradient computation\n","        with torch.no_grad():\n","            # Forward pass\n","            outputs = model(batch)\n","\n","            # Get the predicted values\n","            predicted = outputs.squeeze().numpy()\n","\n","        # Unscaling values\n","        unscaled_target = ConstantUnScaler(y[-1], min_gold, max_gold)\n","        unscaled_pred = ConstantUnScaler(predicted[-1], min_gold, max_gold)\n","\n","        # Append the last unscaled target and prediction to the respective lists\n","        unscaled_targets_list.append(unscaled_target)\n","        unscaled_preds_list.append(unscaled_pred)\n","\n","    # Calculate the RMSE for the current hero\n","    rmse = np.sqrt(mean_squared_error(unscaled_targets_list, unscaled_preds_list))\n","\n","    # Create a dataframe for the current hero with RMSE value\n","    df_results_hero = pd.DataFrame({'rmse': [rmse]})\n","\n","    # Save the dataframe with the hero_id in the name\n","    df_results_hero.to_csv(f'df_results_{hero_id}.csv', index=False)\n","\n","    # Append the hero_id and RMSE to the df_results_all dataframe\n","    df_results_all = df_results_all.append({'hero_id': hero_id, 'avg_rmse': rmse}, ignore_index=True)\n","\n","# Save the df_results_all dataframe\n","df_results_all.to_csv('df_results_all.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxuLGo0Fj5xC"},"outputs":[],"source":["#test = pd.DataFrame(df_allhero[['gold_t']].iloc[0])\n","#test"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}