{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHGBfP1qYH78PNyrEvEoZB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import json\n","import pandas as pd\n","import numpy as np\n","from numpy import array\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","\n","#from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"idW0SA6qiJkt","executionInfo":{"status":"ok","timestamp":1714671584358,"user_tz":240,"elapsed":13008,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/698/10step_5horizon\")"],"metadata":{"id":"jdCoGoY2W7TL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714671608328,"user_tz":240,"elapsed":23982,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}},"outputId":"d3b06521-2c83-4ace-f73b-a43d112addbe"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#%run data_prep_10step_5horizon.ipynb\n","%run LSTM_Model_Classes.ipynb"],"metadata":{"id":"_uLXlLPsM9zQ","executionInfo":{"status":"ok","timestamp":1714671609338,"user_tz":240,"elapsed":1013,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/Colab Notebooks/698/10step_5horizon/data\")\n","df_rf_15 = pd.read_csv('df_rf_15.csv')\n","df_rf_20 = pd.read_csv('df_rf_20.csv')\n","df_rf_25 = pd.read_csv('df_rf_25.csv')\n","df_rf_30 = pd.read_csv('df_rf_30.csv')\n","df_rf_35 = pd.read_csv('df_rf_35.csv')\n","df_rf_40 = pd.read_csv('df_rf_40.csv')\n","df_rf_45 = pd.read_csv('df_rf_45.csv')\n","df2_allhero = pd.read_csv('df2_allhero.csv')\n","df2_all_remain = pd.read_csv('df2_all_remain.csv')\n","heroes= pd.read_csv('heroes.csv')"],"metadata":{"id":"Zw8FNNFoFLWl","executionInfo":{"status":"ok","timestamp":1714672135531,"user_tz":240,"elapsed":987,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/Colab Notebooks/698/\")\n","%run Useful_Functions.ipynb\n"],"metadata":{"id":"t9W9Llj-w8sY","executionInfo":{"status":"ok","timestamp":1714673298783,"user_tz":240,"elapsed":642,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["#df2_allhero"],"metadata":{"id":"Mp6lY8-4OZHQ","executionInfo":{"status":"ok","timestamp":1714671611542,"user_tz":240,"elapsed":5,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/Colab Notebooks/698/10step_5horizon/models\")\n","\n","model_dict = torch.load('10step_5horizon_RMSE_84.pth')\n","#best_model_state = torch.load('10step_5horizon_best_model_RMSE.pth')\n","#best_model_state = torch.load('10step_5horizon_best_model_MAE.pth')"],"metadata":{"id":"8VXdQxJ6OKz-","executionInfo":{"status":"ok","timestamp":1714673370025,"user_tz":240,"elapsed":220,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["df2_70"],"metadata":{"id":"CJ_WRYAft7qC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lookback = 10\n","horizon = 5\n","\n","process_embedding = ProcessEmbedding(df2_allhero, embedding_dim=84, lookback=lookback) # we create the embedding vector on unsplit data to ensure all unique hero id's are contained\n","\n","input_size = process_embedding.embedding_dim + 1 #84 + 1\n","hidden_size = 64\n","num_layers = 2\n","output_size = 5  # Assuming you want to predict 5 values\n","\n","model = LSTMModel(input_size, hidden_size, num_layers, output_size, process_embedding)"],"metadata":{"id":"Wir62aRRQXOI","executionInfo":{"status":"ok","timestamp":1714673372460,"user_tz":240,"elapsed":180,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["index = 5  # Choose the index of the desired time series\n","selected_row = df2_all_remain.iloc[index]\n","\n","# Extract the necessary information from the selected row\n","hero_id = selected_row['hero_id']\n","time_series = np.array(json.loads(selected_row['gold_t'])).astype('float32')\n","\n","# Scale the time series using the same scaling function used during training\n","scaled_time_series = ConstantMinMaxScaler(time_series, min_gold, max_gold)\n","\n","# Create windows from the scaled time series\n","X, y = create_windows(scaled_time_series, lookback, horizon = 5)\n","\n","\n","# Create a batch with the selected time series\n","batch = ((hero_id,), (X,), (y,))\n","\n","# Load our saved model state\n","model.load_state_dict(model_dict)\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","# Disable gradient computation\n","with torch.no_grad():\n","    # Forward pass\n","    outputs = model(batch)\n","\n","    # Get the predicted values\n","    predicted = outputs.squeeze().numpy()\n","\n","\n","#Unscaling values\n","unscaled_targets = ConstantUnScaler(y[:,-5:], min_gold, max_gold)\n","unscaled_preds = ConstantUnScaler(predicted, min_gold, max_gold)\n","\n","# Print the Time Series\n","#print(\"Timeseries:\")\n","#print(time_series)\n","# Print the predicted values\n","#print(\"Targets:\")\n","#print(y[:,-5:])\n","#print(\"Predicted values:\")\n","#print(predicted)\n","\n","# Print Unscaled Targets\n","#print(\"Unscaled Targets\")\n","#print(unscaled_targets)\n","#print(\"Unscaled Preds\")\n","#print(unscaled_preds)"],"metadata":{"id":"H1tdmZASvsXf","colab":{"base_uri":"https://localhost:8080/","height":963},"executionInfo":{"status":"error","timestamp":1714673379045,"user_tz":240,"elapsed":208,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}},"outputId":"c2349ee5-b38d-49fd-a564-b089fcbc32ac"},"execution_count":41,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"expected m1 and m2 to have the same dtype, but got: double != float","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-1f9fcbf137f3>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Get the predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-5a83c4469e27>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Pass combined input to LSTM layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# Take the last 5 outputs of the LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    879\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: double != float"]}]},{"cell_type":"code","source":["scaled_targets = y[:,-5:]\n","scaled_preds = predicted\n","\n","#print(scaled_targets)\n","#print(scaled_preds)"],"metadata":{"id":"kHoCqcdYqbj5","executionInfo":{"status":"aborted","timestamp":1714671611707,"user_tz":240,"elapsed":2,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(unscaled_preds.shape)\n","# print(lookback+horizon-1) # 10 + 5 - 1 = 14\n","# print(len(unscaled_preds)+horizon-1) # 31 + 5 - 1 = 35\n","# print(len(preds_plot)) # 45\n","# print(unscaled_preds[-5:])\n","# #35-14 = 21\n","# preds_plot\n","# time_series"],"metadata":{"id":"ef9adMrYNM3u","executionInfo":{"status":"aborted","timestamp":1714671611707,"user_tz":240,"elapsed":2,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create an array from the unscaled_preds array that contains the values from the first row and the last value of each subsequent row\n","row_one = unscaled_preds[0,]\n","last_of_rest = unscaled_preds[1:,-1]\n","unscaled_preds_series = np.ones_like(time_series) * np.nan\n","unscaled_preds_series[lookback:len(time_series)] =  np.concatenate((row_one, last_of_rest), axis=0)"],"metadata":{"id":"Jnl08cj8SoRP","executionInfo":{"status":"aborted","timestamp":1714671611707,"user_tz":240,"elapsed":2,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(unscaled_targets)\n","\n","print(unscaled_preds_series)"],"metadata":{"id":"Y6zs5WbJj69t","executionInfo":{"status":"aborted","timestamp":1714671611708,"user_tz":240,"elapsed":3,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","horizon = 5  # Number of steps to predict\n","\n","#preds_plot = np.ones_like(time_series) * np.nan\n","#preds_plot[lookback+horizon-1:len(unscaled_preds)+horizon-1] = unscaled_preds[-5:]\n","#preds_plot[14:35] =\n","# Plot actual values\n","plt.plot(time_series, label=\"Whole Timeseries\")\n","\n","# Plot predicted values\n","#plt.plot(unscaled_targets, c='g', label=\"Target Values\")\n","plt.plot(unscaled_preds_series, c = 'r', label = \"Forecasting Predictions\")\n","\n","plt.title(f\"HeroID:{hero_id} Game Length: {len(time_series)} Minutes, Lookback Window: {lookback}\")\n","\n","# Add a label to the x-axis\n","plt.xlabel('Timestep (Minute)')\n","\n","# Add a label to the y-axis\n","plt.ylabel('Gold')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"uIGs399zMgUp","executionInfo":{"status":"aborted","timestamp":1714671611708,"user_tz":240,"elapsed":3,"user":{"displayName":"Daniel Craig","userId":"14982667842642761541"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qWLdXYfbj5xC"},"outputs":[],"source":["import pandas as pd\n","from sklearn.metrics import mean_squared_error\n","\n","# Create an empty dataframe to store the average RMSE scores for each hero\n","df_results_all = pd.DataFrame(columns=['hero_id','match_id','rmse'])\n","\n","# Get the unique hero_ids from the dataframe\n","hero_ids = df_all_remain['hero_id'].unique()\n","\n","# Loop over each hero_id\n","for hero_id in hero_ids:\n","    #print(\"Hero_ID: \", hero_id)\n","    # Filter the dataframe for the current hero_id\n","    hero_df = df_all_remain[df_all_remain['hero_id'] == hero_id]\n","    #hero_df = hero_df.iloc[:3] # Used to restrict how large the df is\n","    #print(\"Hero_df: \", hero_df)\n","\n","    # Create empty lists to store the unscaled targets and predictions for the current hero\n","    #unscaled_targets_list = []\n","    #unscaled_preds_list = []\n","\n","    # Loop over each record for the current hero\n","    for index, row in hero_df.iterrows():\n","        # Extract the necessary information from the row\n","        match_id = row['match_id']\n","        print(\"Hero ID: \", hero_id, \"Index: \", index, \"Match ID: \", match_id)\n","        time_series = np.array(row['gold_t']).astype('float32')\n","\n","        # Scale the time series using the same scaling function used during training\n","        scaled_time_series = ConstantMinMaxScaler(time_series, min_gold, max_gold)\n","\n","        # Create windows from the scaled time series\n","        X, y = create_windows(scaled_time_series, lookback , horizon)\n","\n","        # Create a batch with the selected time series\n","        batch = ((hero_id,), (X,), (y,))\n","\n","\n","        # Set the model to evaluation mode\n","        model.eval()\n","\n","        # Disable gradient computation\n","        with torch.no_grad():\n","            # Forward pass\n","            outputs = model(batch)\n","\n","            # Get the predicted values\n","            predicted = outputs.squeeze().numpy()\n","            #print(\"Predicted: \", predicted)\n","\n","        #print(\"Y: \", y)\n","        #print(\"Y[:-5]: \", y[:,-5:])\n","        #print(\"Predicted: \", predicted)\n","        # Unscaling values\n","        unscaled_target = ConstantUnScaler(y[:,-5:], min_gold, max_gold)\n","        unscaled_pred = ConstantUnScaler(predicted, min_gold, max_gold)\n","\n","        # Append the last unscaled target and prediction to the respective lists\n","        #unscaled_targets_list.append(unscaled_target)\n","        #unscaled_preds_list.append(unscaled_pred)\n","\n","    # Calculate the RMSE for the current hero\n","\n","        #print(\"Unscaled Targets: \", unscaled_target)\n","        #print(\"Unscaled Preds: \", unscaled_pred)\n","        rmse = np.sqrt(mean_squared_error(unscaled_target, unscaled_pred))\n","\n","    # Create a dataframe for the current hero with RMSE value\n","\n","        df_results_hero = pd.DataFrame({'hero_id': hero_id, 'match_id': match_id, 'rmse': rmse, 'unscaled_target': [unscaled_target], 'unscaled_pred':[unscaled_pred]})\n","        #print(\"DF Results Hero: \", df_results_hero)\n","\n","    # Append the hero_id and RMSE to the df_results_all dataframe\n","        df_results_all = pd.concat([df_results_all, df_results_hero], ignore_index = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxuLGo0Fj5xC"},"outputs":[],"source":["df_results_all"]}]}